{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yaafelib import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df=pd.read_csv(\"speech-accent-archive/speakers_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.ix[:,11].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df[demo_df.ix[:,11]==\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=\"/home/kavin/Silo/CollegeWork/DeepLearning/Project/split/\"\n",
    "split_audiofiles = [join(dir_path, f) for f in listdir(dir_path) if isfile(join(dir_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_filename_prefix=list(demo_df[demo_df[\"country\"]=='usa'][\"filename\"])\n",
    "india_filename_prefix=list(demo_df[demo_df[\"country\"]=='india'][\"filename\"])\n",
    "selected_prefixes=us_filename_prefix+india_filename_prefix\n",
    "#selected_prefixes=[us_filename_prefix[10], india_filename_prefix[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_audiofiles=[]\n",
    "for audiofile in split_audiofiles:\n",
    "    #if(audiofile.split('_')[0] in selected_prefixes):\n",
    "        #selected_audiofiles.append(join(dir_path, audiofile))\n",
    "    selected_audiofiles.append(join(dir_path, audiofile))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_audiofiles=[\"/home/kavin/Silo/CollegeWork/DeepLearning/Project/speech-accent-archive/recordings/english104.mp3\", \n",
    "                    \"/home/kavin/Silo/CollegeWork/DeepLearning/Project/speech-accent-archive/recordings/bengali11.mp3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_audiofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_select=[]\n",
    "y_select=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audiofile in split_audiofiles:\n",
    "    country=demo_df[demo_df[\"filename\"]==audiofile.split(\"/\")[-1].split('_')[0]][\"country\"].item()\n",
    "    #country=demo_df[demo_df[\"filename\"]==audiofile.split(\"/\")[-1].split(\".\")[0]][\"country\"].item()\n",
    "    \n",
    "    fp = FeaturePlan(sample_rate=44100, resample=True)\n",
    "    fp.addFeature('mfcc: MFCC blockSize=1024 stepSize=512')\n",
    "    fp.addFeature('energy: Energy blockSize=1024 stepSize=512')\n",
    "    fp.addFeature('loud: Loudness blockSize=1024 stepSize=512')\n",
    "    fp.addFeature('sharp: PerceptualSharpness blockSize=1024 stepSize=512')  \n",
    "    fp.addFeature('flat: SpectralFlatness blockSize=1024 stepSize=512')\n",
    "    fp.addFeature('sr: SpectralRolloff blockSize=1024 stepSize=512')\n",
    "    fp.addFeature('sf: SpectralFlux blockSize=1024 stepSize=512')\n",
    "    df = fp.getDataFlow()\n",
    "\n",
    "    # configure an Engine\n",
    "    engine = Engine()\n",
    "    engine.load(df)\n",
    "    # extract features from an audio file using AudioFileProcessor\n",
    "    afp = AudioFileProcessor()\n",
    "    afp.processFile(engine,audiofile)\n",
    "    feats = engine.readAllOutputs()\n",
    "    feature_names=[\"mfcc\", \"energy\",\"loud\",\"sharp\",\"flat\",\"sr\", \"sf\"]\n",
    "    #print(feats.values()[0].shape)\n",
    "    extracted_features=np.hstack([feats.get(key, []) for key in feature_names])\n",
    "    #print((extracted_features.shape[0], 1))\n",
    "    #print(country)\n",
    "    y_select.append(np.full((extracted_features.shape[0], 1), country))\n",
    "    x_select.append(extracted_features)\n",
    "    \n",
    "x_select=np.vstack(x_select)\n",
    "y_select=np.vstack(y_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5114343, 42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices=range(x_select.shape[0])\n",
    "np.random.shuffle(rand_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=rand_indices[:int(x_select.shape[0]*0.6)]\n",
    "val_index=rand_indices[int(x_select.shape[0]*0.6): int(x_select.shape[0]*0.8)]\n",
    "test_index=rand_indices[int(x_select.shape[0]*0.8): x_select.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5114343"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_index)+len(val_index)+len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_labels=list(np.unique(y_select))\n",
    "\n",
    "labels=[country_labels.index(c) for c in y_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=tf.one_hot(labels, len(country_labels)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_select=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save={\"train\":{\"features\":x_select[train_index], \"labels\":labels[train_index], \"feature_names\":feature_names, \"label_names\":country_labels},\n",
    "           \"validation\":{\"features\":x_select[val_index], \"labels\":labels[val_index], \"feature_names\":feature_names, \"label_names\":country_labels},\n",
    "           \"test\":{\"features\":x_select[test_index], \"labels\":labels[test_index], \"feature_names\":feature_names, \"label_names\":country_labels}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"accent_data.npy\", data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def init_bias(shape):\n",
    "    return tf.Variable(tf.ones(shape))\n",
    "\n",
    "def fully_connected_model(params, MODE, data):\n",
    "    \n",
    "    num_hidden_layers=1\n",
    "    hidden_layer_size, learning_rate, minibatch_size, epoch = params\n",
    "    \n",
    "    input_layer_size=15\n",
    "    output_layer_size=2\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, input_layer_size])\n",
    "    \n",
    "    W1 = init_weights([input_layer_size, hidden_layer_size])\n",
    "    b1 = init_bias([hidden_layer_size])\n",
    "    \n",
    "    W2 = init_weights([hidden_layer_size, output_layer_size])\n",
    "    b2 = init_bias([output_layer_size])\n",
    "    \n",
    "    h1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "    y = tf.nn.softmax(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, output_layer_size])\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    #sess.run(init)\n",
    "    # Train\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data[\"train\"][\"features\"], data[\"train\"][\"labels\"]))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(minibatch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                batch_xs, batch_ys = sess.run(next_batch)\n",
    "                assert batch_xs.shape[0] == batch_ys.shape[0]\n",
    "                #print(batch_ys.eval().shape[0])\n",
    "                sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "                acc, loss=sess.run([accuracy, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "                print(\"Train Iteration: {}, Loss: {}, Accuracy: {}\".format(i, loss, acc))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        \n",
    "    if(MODE==\"Tune\"):\n",
    "        return(sess.run([accuracy, cross_entropy], feed_dict={x: data[\"validation\"][\"features\"], y_: data[\"validation\"][\"labels\"]}))\n",
    "    elif(MODE==\"Test\"):\n",
    "        return(sess.run([accuracy, cross_entropy], feed_dict={x: data[\"test\"][\"features\"], y_: data[\"test\"][\"labels\"]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(\"x_usa_india.npy\")\n",
    "labels = np.load(\"y_usa_india.npy\")\n",
    "\n",
    "country_labels=list(np.unique(labels))\n",
    "\n",
    "labels=[country_labels.index(c) for c in labels]\n",
    "\n",
    "labels=tf.one_hot(labels, len(country_labels)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_data=np.load(\"accent_data_usa_india.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size, learning_rate, minibatch_size, num_epoch = (30, 1e-4, 64, 10)\n",
    "params=(hidden_layer_size, learning_rate, minibatch_size, num_epoch)\n",
    "\n",
    "fully_connected_model(params, \"Tune\", accent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes=[50,100,300]\n",
    "learning_rates=[0.1, 1e-3, 1e-5, 1e-7]\n",
    "minibatch_sizes=[64,128]\n",
    "epochs=[15000, 20000]\n",
    "MODE=\"Tune\"\n",
    "hyperparameters = [hidden_layer_sizes,learning_rates, minibatch_sizes, epochs]\n",
    "all_parameter_combinations=list(itertools.product(*hyperparameters))\n",
    "costs=[]\n",
    "accuracies=[]\n",
    "for parameter_combo in all_parameter_combinations:\n",
    "    hidden_layer_size, learning_rate, minibatch_size, num_epoch = parameter_combo\n",
    "    acc, cost=fully_connected_model(params, MODE, accent_data)\n",
    "    costs.append(cost)\n",
    "    accuracies.append(acc)\n",
    "    print(\"Hidden Layer Size: {}, Learning Rate: {}, Minibatch Size: {}, Number of Epochs: {}, Validation Cost: {}, Validation Accuracy: {}\".\n",
    "      format(hidden_layer_size,learning_rate,minibatch_size,num_epoch,cost,acc))\n",
    "\n",
    "best_params=all_parameter_combinations[np.argmin(costs)]\n",
    "print(\"Best Parameters: \\n Hidden Layer Size: {}, Learning Rate: {}, Minibatch Size: {}, Number of Epochs: {}\".\n",
    "        format(best_params[0],best_params[1],best_params[2],best_params[3]))\n",
    "params=best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "features_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "# [Other transformations on `dataset`...]\n",
    "dataset = ...\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: features,\n",
    "                                          labels_placeholder: labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.uniform(0, 1, (10, 5))\n",
    "b=np.random.choice([0, 1], (10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((a, b))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y=next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "print(sess.run(next_element)) \n",
    "print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
